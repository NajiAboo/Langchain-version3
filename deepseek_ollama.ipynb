{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepseek-R1 \n",
    " ### Deepseek-r1 is a large language open source model that focuse on reasoning. It can handle tasks that need multi-step problem-solving and logical thinking. The model uses special trianing method that put special emphasis on Reinformcement Learning instead of Supervised Fine Tuning. This approach helps the model to be better at figuring things out on its own\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "### - Deepseek-r1 local installation using Ollama\n",
    "### - Run with curl command\n",
    "### - Use Openai's completion api with Deepseek-r1\n",
    "### - Integration with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1/\",\n",
    "    api_key=\"ollama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "       { \"role\":\"User\", \"content\":\" Say this is a test\"}\n",
    "    ],\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\n\\n</think>\\n\\nHi! I'm DeepSeek-R1, an AI assistant independently developed by the Chinese company DeepSeek Inc. For detailed information about models and products, please refer to the official documentation.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    prompt=\"Say this is a test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-675', choices=[CompletionChoice(finish_reason='stop', index=0, logprobs=None, text=\"<think>\\n\\n</think>\\n\\nNo, I'm an AI assistant created exclusively by DeepSeek, so I don't have access to or knowledge of tests. I'm here to help with any questions or tasks you need assistance with. How can I assist you today?\")], created=1737733696, model='deepseek-r1:1.5b', object='text_completion', system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=52, prompt_tokens=8, total_tokens=60, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='deepseek-r1:1.5b', created=1737730981, object='model', owned_by='library'), Model(id='hf.co/prithivMLmods/Llama-Deepsync-1B-GGUF:F16', created=1735807159, object='model', owned_by='prithivMLmods'), Model(id='hf.co/mradermacher/Triangulum-1B-i1-GGUF:IQ1_M', created=1735806575, object='model', owned_by='mradermacher'), Model(id='hf.co/stabilityai/stable-code-3b:latest', created=1735804975, object='model', owned_by='stabilityai'), Model(id='phi3:latest', created=1735200411, object='model', owned_by='library'), Model(id='llama3.2:1b', created=1735052341, object='model', owned_by='library'), Model(id='moondream:latest', created=1735051894, object='model', owned_by='library')], object='list')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model=\"deepseek-r1:1.5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\n\\n</think>\\n\\nSure! Here's a light-hearted joke:\\n\\nWhy donâ€™t skeletons fight each other?  \\nBecause they donâ€™t have the *gym*!! ðŸ˜„\", additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-01-24T15:49:48.470778Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1776082667, 'load_duration': 37824083, 'prompt_eval_count': 7, 'prompt_eval_duration': 596000000, 'eval_count': 36, 'eval_duration': 1140000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-1379ed4c-61cf-4502-bfaf-fd51ea9af0f1-0', usage_metadata={'input_tokens': 7, 'output_tokens': 36, 'total_tokens': 43})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
